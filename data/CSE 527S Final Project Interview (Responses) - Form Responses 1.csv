Timestamp,"By selecting the ""I agree"" button option, you indicate that you have read the information provided above, that you voluntarily agree to participate in this study, and that you are at least 18 years of age.",What is your field of study?,"If you are pursuing an undergraduate degree, what year are you in? If you are pursuing graduate degree (including dual degree students) what is the degree you are pursuing? If you are a faculty, what is your position? 

(Please utilize ""Other..."" option and enter accordingly if there are no available options below or you are not clear about the options or you believe the options may not accurately reflect your response)",How would you rate your familiarity with LLMs?,How well do you trust LLM's?,"If you have any experience working with/using LLM, please list/describe any of them. ","In what area do you think LLMs will be most used in the future? (e.g., education, healthcare, entertainment, programming, content generation, law etc.)",What specific tasks or functions do you envision LLMs being used for in that area in the future (other than those mentioned above)?,"Given your academic/professional background, what security vulnerabilities or privacy risks do you think might arise from the increased reliance on LLMs in everyday tasks and interactions in your field","In your opinion, what are some possible ways that LLMs could be exploited for malicious purposes in the future, given their ability to generate highly convincing and human-like content?","In what ways might LLMs compromise user privacy or security, and what measures can be implemented to protect sensitive information?",What other risks do you think could arise from the reliance of LLMs in your field in the future?,"Do you see any specific industries or sectors that might be particularly vulnerable to attacks leveraging LLMs in the future?""","In what ways can interdisciplinary collaboration between experts in AI, ethics, law, psychology, and other fields help identify and mitigate the risks associated with LLMs?","Do you believe LLMs should have the capability to fingerprint users and identify them based on their inputs? If yes, do you foresee any potential privacy or security risks associated with this feature?","With the development of AI models that can understand text, images, and audio together, do you think there could be any additional security concerns? List those concerns below",How well do you Trust LLM's now?,Your Email,Are you willing to participate in 10 minutes virtual or in-person follow-up interview?,Your Name,What days and times are you free this week or next week?,"What is your field of study/major/profession?

(Please utilize ""Other..."" option and enter accordingly if there are no available options below or you are not clear about the options or you believe the options may not accurately reflect your response)",What is the 
3/23/2024 16:38:40,,Computer Science,Masters/Dual Degree,8,8,N/A,Data analysis,help people understand their data better,N,Help terrorist make bomb,N,N,N,N,N,N,,,No,,,,
3/25/2024 10:23:40,I agree,Engineering,Senior,5,3,utilizing ChatGPT， image generation service,healthcare,perform diagnosis and interact with patient,"untrustworthy information generation (code, fact, etc.)","phishing, spamming, impersonation",information leakage - no cache policy,unemployment,"SDE, customer service",companies have an incentive to disregard ethics and user privacy. Laws are too slow to catch up.,"yes. Much like search engine, profiling would be problematic.",,3,,No,,,,
3/25/2024 10:46:08,I agree,Engineering,Professor,10,1,Use them to understand LLMs so that I can carry out research on this topic. ,Almost all aspects of life,Almost all aspects of life,A lot,A lot,A lot,A lot,A lot,A lot,A lot,A lot,1,umar.iqbal@wustl.edu,Yes,Umar Iqbal,Monday 12:30 to 1:30 or after class,,
3/25/2024 14:04:38,I agree,Arts and Science,Sophomore,3,5,"chatGPT, google translate",healthcare,"analyzing and communicating patient feedback, ","people's private information being shared after they give it to an LLM, ",LLMs might have the potential to be very good at scam calls and other scams. ,they may take in information about people's personal lives and accidentally share it later. i don't know what measures could be implemented to protect people's information,"in my field, data science, use of LLMs on data has the potential to leak sensitive information that should not be shared. additionally, LLMs may not have a clear understanding of data ethics.","yes, I think healthcare may be because they have a duty to respond to people in need, which large language models could take advantage of.","a combined approach between many fields can mitigate the risks associated with AI through an understanding of the many different ways LLMs, which can simulate human emotion well, can be abused to take advantage of people and the ways in which people are vulnerable can be protected","Yes, I think they should. I foresee many privacy risks, as whoever owns the data for the LLM could see a lot of information about a person","yes. I think that it may become harder to identify AI from people, especially when interacting virtually. people could easily be taken advantage of by AI",3,h.l.woodhouse@wustl.edu,Yes,Hannah Woodhouse,"Wednesday, Friday after 2:00, Tuesday Thursday between 10 and 12 and 4 and 5:30",,
3/25/2024 14:24:00,I agree,Engineering,Junior,1,3,"Rare use of ChatGPT, frequent use of Google Translate. ",Programming,"Debugging code, providing sample programs.","Negligence to verify sources of information
Unregulated harvesting of data for training LLMs (this is already an issue with art-generating GPT platforms). 
Fabricated, non-consensual photos or videos of individuals",More-sophisticated online scamming,"Jailbreaking, for the purpose of revealing proprietary information. ","Casual mistreatment of AI.
Accidental use of false information.","Education, specifically any institution which weights LLM use over the employment and support of human teachers. ","Monitor and prohibit use of data containing personal identifiers or information in training. 
Educate public on effective use (and potential misuse) of LLMs. ","This question depends on the purpose of the LLM.
Should an LLM be trained on sensitive, private, confidential, or otherwise non-civilian information (ex. for government or internal corporate use), fingerprinting would be an effective security deterrent against misuse, and would provide accountability. 
However, for public LLMs, fingerprinting seems excessive. 
In both cases, I believe any training of LLMs on fingerprint data is a terrible idea. ","Impersonation.
Non-consensual fabrication of videos or photographs of individuals. 
Synthesis of false quotes by individuals. ",2,m.takato@wustl.edu,No,,,,
3/26/2024 12:12:45,I agree,Engineering,Masters/Dual Degree,7,5,"I use a smart speaker at home, and ChatGPT everyday for different coding related tasks.",I think healthcare will be a major area in which LLMs are used. ,I think they could be good for people who don't have good access to healthcare and need some rudimentary checkup. ,I think too much dependence on LLMs will lead to more code vulnerabilities or possibly more predictable code that is easier to exploit due to increased usage in LLM generated code. ,"hacking a company, or using AI to attack other models. ",It could be using prompts to learn in bad ways that produce harmful outputs. ,"People may lose their knowledge level for coding, or become less innovative ",Marketing or telemarketing could be vulnerable if AI callers are unpredictable and start scamming people. ,Continue to conduct research and test different methods of attacks ,"I think it is possible for LLMs to be able to do this, however, I think that this presents multiple privacy concerns related to ads and tracking. ",I think using real people in images or audio and having AI generate possible false scenarios with those people could be harmful. ,5,haffnerriley@wustl.edu,No,,,,
3/27/2024 18:54:06,I agree,Arts and Science,Junior,1,5,Use google translate almost daily,Healthcare,Way to enter in all symptoms and find precedent for cases,False information about climate change ,Political propaganda spreading false information ,May collect data based on inquiries - provide warnings to users and educate students on ai use eariy,"A large portion of my field has to do with human interactions, understanding, and empathy - none of which llms truly possess",Military ,Many - no entity used for universal use can be created without universal input,No,Things could be taken out of context in a dangerous way,3,Cate@wustl.edu,No,,,,
3/27/2024 19:13:58,I agree,Nursing,Junior,4,3,ChatGPT,Any media such as films and commercials ,Creating actors without actually hiring actors to save money ,Creating fake evidence of a crime or using it to view people in inappropriate ways ,Using it to view people in vulnerable and inappropriate ways ,They can pretend to be someone else to trick you into giving information. Measures could be whoever has created the LLMs must program them to able to recognize when someone is trying to manipulate it and give the user an error. Terms and conditions could be set up and a real person could monitor conversations and flag anyone who tries to manipulate LLMs.,Taking away jobs ,Not sure ,Find someone qualified enough to monitor all interactions ,No ,,2,,No,Alyssa ,,,
3/27/2024 19:18:32,I agree,Chemistry,Senior,3,1,I don't use them,I think they will be useful in law.,They're good for collecting data/background/precedent for cases. They're good to dig through a historical record of law cases and find suits that fit a specific circumstance.,I think prompt interjection is a big risk. Especially when you have large groups of students entering in similar or exactly the same questions into an LLM.,"Deep fakes are especially concerning. In an age where media is so ubiquitous and there's a constant access to film and pictures and news, there is a big lack in teaching the thinking skills to maneuver a landscape that can deal in falsehoods and fakes. Not to mention they are getting so believable and realistic that discerning the truth can get harder. This is an opportunity to promote misinformation and cause panic/frenzy.",I think people put a blind trust in these programs which leaves them vulnerable to attacks like prompt interjection.,I think people lose the ability to critically reason with the information they're given. Why learn calculus if you can look up a solution? We will see a sharp degradation in prerequisite knowledge and the number of people with useful and workable skills will begin to decrease.,I can't think of any specific industries. ,I think legislation passed limiting how these machines can be used would be ideal. Limit access to them and limit what they can do.,No. This is a huge risk to have such valuable personal identification stored into such a novel and complex platform that can be subject to abuse.,Deep fakes,1,,No,,,,
3/27/2024 19:44:09,I agree,Computer Science,industry,6,7,chatgpt,knowledge lookup,ask a question get a data enriched answer,people trusting output to be true too much,scam automation,training on pii or being given access to pii for augmentation,decrease in level of deep understanding,i think they unlock a whole new scale for social engineering,figure out how to teach people about the dangers,"doesn't matter but it should be highly regulated if so, see GDPR",evidence in court will be harder to prove,6,,No,,,,
3/27/2024 20:06:37,I agree,Arts and Science,Senior,3,4,"Using ChatGPT, Google Translate, DALLE",Content generation ,Advertising,"Since I may work in healthcare, using LLMs to interact with patients may cause PHI to be accessed by the models, which could become a security/privacy risk if the model acts on this information in a dangerous way  ",Possibly things like deepfakes and manipulation by imitating specific people such as loved ones,"Depending on the model, they could be hacked (?) which could compromise security. Measures like human oversight could protect against this",Elimination of human jobs as well as necessary human judgment/experience,"Not sure, maybe those that involve a lot of subjective accounts like criminal justice?",Perhaps by identifying vulnerabilities and identifying where human oversight is needed,"I don’t think they should, as this could put them at risk of leaking their biometric data?","Yes, this could potentially allow convincing impersonation ",4,aramiah@wustl.edu,Yes,Ashna Ramian,"Friday April 5th after 3:50, any time besides 5-8 Sunday April 7th",,
3/27/2024 20:46:23,I agree,Psychology ,Junior,1,4,Chat GPT,Content generation,Helping with caretaking tasks,HIPPA violations and unsafe untested psychological advice,"They could be used to fake videos and content inspiring violent acts. For example, using Obama to start a riot. It could also ruin a lot of ppls careers.",Don't share private information with AI's.,Exploiting people for money,Healthcare and Education.,There can be laws preventing LLMs from crossing certain lines. Such us using LLMs to teach our nurses and doctors.,"Absolutely not. Yes, it could be used to steal confidential information.",Yes. Deep fakes,2,mwanjoya231@gmail.com,No,Mary,,,
3/27/2024 20:56:10,I agree,Nursing ,Junior,1,5,I have used ChatGPT,"As we can see now they are very popular especially in education; right now students across the world and even businesses are utilizing to generate income through their niches. Additionally, we can see it in programming and content generation, so in the future it will continue expanding in those areas, hopefully we don’t see it in healthcare as it would be jeopardizing a lot of things in that area.","I think it can be used as the new social media and people interactions, this will lead to social interaction and physical interaction being zero to none.",People being completely dependent on it especially during their studies for the profession which could lead to them not fully understanding and knowing what they are doing or how they are doing it ,Being able to access people’s personal data without being detected or even medical records.,Everyone can avoid sharing personal information with LLM if they end up using them. ,Them being able to access and even do human activities like finger printing or even cloning information like that.,"Sectors that involve technology like computer science, education etc",They can come with restrictions that limit LLM capabilities and accessibility to general population ,"No, this will lead to an easier way of Identification theft ","Cloning, mimicking, and even diagnosing especially in healthcare settings, people may begin to rely on LLMs for medical treatment ",1,brendacharles64@gmail.com,Yes,Brenda,In the morning from 10 to 1,,
3/27/2024 23:32:21,I agree,Arts and Science,Junior,4,5,"I’ve used ChatGPT and it’s been proven to be useful and generally accurate. There are times where the response that is generated is wrong, but in terms of brainstorming for ideas it does a pretty good job. Google translate is also helpful for when communication becomes a barrier when you are conversing in a different language, but like other LLMs it does have times where it is inaccurate.","LLMs will be mostly used in education, simply because it has become another medium as a search engine for students to use to find answers to homework problems and assignments.",LLMs can also be used as a way to expose an individual to different perceptions and thinking processes. ,It would be easy to check the history of the things that you searched for and asked questions on.,It can be used to guide an individual’s way of thinking that may be out of character for them.,"If LLMs is hacked, then all information will be exposed and can be exploited by hackers.","There is creativity in the answers that LLMs give, because human brains are complex and computers are a reflection of what human brains had thought about in the moment.",Cybersecurity may be vulnerable to such attacks.,They can give it continuous updates so that it aligns with how our society is progressing.,,,5,shirleymlin4@gmail.com,No,Shirley,,,
3/28/2024 0:47:41,I agree,Arts and Science,Junior,5,6,Using ChatGPT and DALLE for academic + leisure tasks,Programming,Debugging code,Using ChatGPT to gain access to password protected information online,The use of things like Sora to make deepfake videos,Using LLMs to speed up password-cracking processes,A bias in philosophical decisions towards a certain worldview backed-up by poisoned training data,"Academia, finance","Listening to the input of sociologists, cultural scholars, or anyone else who studies the kind of data and discourse that is being uploaded online to help anticipate certain biases in training data","I do not -- I feel that that could lead to the capability to generate entirely new (but believable) human fingerprint designs, which could further be used for fraud",Face-tracking data could be used to provide extensive details about a person's location ,6,hapeman.l@wustl.edu,No,,,,
3/28/2024 11:33:44,I agree,Arts and Science,Senior,2,5,I have experience with sites like Google Translate and DeepL as a foreign language major but no experience with ChatGPT or image generation services. ,"I think LLMs can be really positive for things like education, healthcare, and law. I do have reservations with LLMs in regards to more creative domains (for example, using AI to generate visual art or writing) but I'm sure there are some positive ways to leverage LLMs in these areas as well.","I feel like LLMs could be good for increasing efficiency in a lot of different areas. For example, they could help doctors with diagnosing patients.","I'm looking to become a doctor, and I think that since there is a lot of sensitive and private information that is handled by healthcare professionals this can pose a big risk with regards to reliance on LLMs, for example if there were to be a jailbreaking attack that bypassed the system's security. ","I think LLMs can definitely be used to exploit or extort people or convince them to do things they wouldn't otherwise do. For example, I think that the ability to produce things like deepfakes is uncanny and can be leveraged for malicious purposes. ","I'm not totally sure about this question, but I feel like upping cyber security and creating laws about how LLMs are used/what data they are allowed to collect can help prevent sensitive information. ","Decrease in creativity, exposure to jailbreaks, hyperdependence on technology as opposed to oneself, depersonalization of medical treatment","Potentially healthcare, government agencies, insurance companies, etc. ",I think understanding the ethical limits of LLMs and what they should and can be reasonably used for in our society is a perspective that interdisciplinary collaboration between experts can provide. ,,,5,g.heather@wustl.edu,No,,,,
3/28/2024 16:30:09,I agree,Engineering,Masters/Dual Degree,7,5,"smart speaker, chat gpt","Programming, content creation","Generating code, debugging and error handling. giving suggestions. ","Data security issues, jailbreak exploits.",It could be used to extract secure data. It could also be used to generate answers which are considered unethical or illegal. ,LLMs should not be provided with sensitive information.,data leakage.,Computer science and medical industries.,LLMs can be controlled and their output could be restricted to avoid issues.,"No, i dont think they should have the capability to fingerprint users.",Fake videos with similar voices of a real human being could be generated to spread misinformation.,5,s.s.upadeo@wustl.edu,No,Soham Upadeo,Friday,,
3/28/2024 17:08:02,I agree,Arts and Science,Senior,8,8,Helping me study by testing me ,Engineering ,Transportation routes  ,Lack of creativity ,Writing scripts ,NA,NA,Creative fields ,NA,"Yes, yes but not sure ",NA,9,Church.d@wustl.edu,No,Max Church,I’m not ,,
3/28/2024 17:17:16,I agree,Arts and Science,Senior,2,5,Google translate,"Programming, science, government",Writing long reports and being used to synthesize data,Using any sort of data or analysis method for data that is incorrect,Forgeries and plagiarism,NA,Data validity,"Media coverage, fake news reporting",NA,"Yes, but fingerprints are also used often for passcodes",Surveillance,3,Alana.herr4@gmail.com,No,,,,
3/28/2024 17:17:47,I agree,Arts and Science,Senior,5,3,"Chat gpt, google translate",Business writing ,Replacing any writing tasks,Personal data mining,Using LLMs to spew hate speech  ,Don’t make the LLMs capable to do certain tasks,Taking over jobs,Artist or writing jobs,Figure out how to recognize what’s ai generated,They should not be able to,,2,L.rey@wustl.edu,No,Lilliana Rey,,,
3/28/2024 17:23:33,I agree,Arts and Science,Freshman,1,10,N/A,Healthcare,Not sure,N/A,NA,NA,NA,NA,NA,NA,NA,10,j.m.nurenberg@wustl.edu,No,Jack,None,,
3/28/2024 17:26:55,I agree,Arts and Science,Freshman,5,8,"I use them occasionally to make things easier, but I don’t rely on them in any significant way.",I think it’ll be used to comb through the internet for relevant information like a search engine within a search engine. It’ll combine results and cross reference sources.,Maybe it’ll do research or assist in it?,NA,NA,"They might collate data about a person to find password options, as it’s common to use combinations of birthdays, pet names, etc. as passwords.",NA,NA,"I think it would be hard to, especially because of how fast they are changing and growing",NA,NA,7,a.q.du@wustl.edu,No,,,,
3/28/2024 17:29:24,I agree,Arts and Science,Sophomore,3,3,I use Chat GPT occasionally to write emails.,I think that it will be used for all those things. I think that lots of writing will be done by AI in the future. I think the exceptions may be legal decisions and things involving humor. ,I also see large language models being used for language translation. I also seem them being used for speech writing and in politics.,"I think the fact that LLMs can access so much data is nerve-wracking. In poli sci and in the legal field, we talk about the right to privacy a lot. Part of that is the right to be forgotten. If you can types someone’s name into an LLM and receive tons of info about them, you could easily scam or impersonate them, and you could also dig up old things that hurt someone’s right to be forgotten. ","Scams in general. They could create phishing emails, impersonate loved ones, or be used to trick people into thinking they  are receiving a letter of some kind that they actually aren’t. I’m thinking specifically about someone receiving a cease and desist letter or a fake warrant.",NA,"People losing their jobs and being replaced by LLMs, or LLMs skewing the work of academia, or writing biased work ","Sales, ethics",NA,"No, it’s a privacy violation and risk. They can be hacked. ","People impersonating loved ones to scam others, people creating fake videos that implicate someone.",2,e.wierich22@gmail.com,No,,,,
3/28/2024 17:37:08,I agree,Business,Freshman,1,6,NA,Programming,Creating programs and assisting programmers,NA,NA,NA,NA,Healthcare,NA,No,NA,5,andreleger25@gmail.com,No,,,,
3/28/2024 17:42:43,I agree,Arts and Science,Sophomore,1,3,Have used ChatGPT in the past as a way to get ideas for things. Use Google translate for my language homework. ,I think it will most be used in education because of the ease of use and the stress culture that is present within education may cause this fast approach to writing papers as appealing,Mostly for writing purposes,Might be stealing sensitive data and users are unaware ,To create fake content that may be harmful,NA,Plagarism and lack of authenticity ,Politics,NA,NO,Maybe in regard to how this data could be used in a malicious manner,3,n.m.umana-ramos@wustl.edu,Yes,Noé Umaña-Ramos,"None this week, but free M, W after 7 PM, T, TH after 5:30",,
3/28/2024 17:44:59,I agree,Business,Sophomore,5,9,"ChatGPT, Bard, Gemini, WUSTL AI",Content generation for entertainment,"Brainstorming, writing scripts, writing jokes, revising snd editing grammar","People will be more vulnerable to scams, false information, and for breaches of data privacy","Impersonating people (or government) more accurately, sneakily providing false information, and convincing people to shift their opinions relevant to political issues",The user shouldn’t give it any private information ,Making suggestions that aren’t strategically advisable,Politics; media,Government regulation,No,NA,8,Bergman.s@wustl.edu,Yes,Stephanie Bergman,,,
3/28/2024 17:45:47,I agree,Arts and Science,Freshman,2,3,"ChatGPT, Snap AI",i think that LLMs will be most used in entertainment (like the movie Wish) that movie sucked and it was written by robots. i think education. ,government,maybe chat gpt detect like cheating on assignments with it. selling our data. ,deep fakes: my parents fall for deep fakes on tik tok,"they just see what we are asking and sell our data. i don’t know how they wouldn’t sell our data, maybe the government do something abt it",lack of human touch (things just so robotic),"i’m not really sure, google?",working with the government to create more security. ,maybe identify; seeing what type of questions we ask and tailor to ourselves. ,yes! i fear that someone could hack into the system and get personal information from these images:(,4,l.a.lopez@wustl.edu,No,Lizy Lopez,N/A,,
3/28/2024 17:47:58,I agree,Arts and Science,Alum,5,6,I use large language models to get answers to specific questions that I don’t think Google will answer quite as quickly.,I think large language models will probably take over search in someway? And also help increase productivity and all fields.,"I work in financial services. At the moment, I think large language models restrict information on large language models. I would like to use large language models to help answer, much more specific, financial questions, and also help me build financial models, and scour financial documents.",I think it’s very important that the sources of large language models are more transparent. I think it’s very dangerous if people rely on information where they have no idea where the source comes from.,"Large language, models might help people build dangerous devices, such as bombs, help bad actors, advertise towards people, and try manipulate them.","It would be very dangerous of large language. Models helped bad actors, infiltrate other peoples data.","If people become too relying on large language, models and large language models produce false information, that could lead to the spread of incorrect information which is dangerous. ",Advertising. ,Managing the inputs to the large language models.,I don’t see the need for this. ,Absolutely there are additional security concerns. These models can help bad actors.,3,nr06880@gmail.com,No,Noah Robins,,,
3/28/2024 17:48:05,I agree,Arts and Science,Freshman,8,2,I’ve only used chat gpt but am familiar with their workings. ,Entertainment and education. ,Studios will probably not want to pay writers or animators and just use ai. And schools may do the same with teachers. ,"Data selling, incription, deep fakes, non human arts. ","Data selling, ","Government can restrict it a little, and users can just not sign up for it if they do that. ","Human interaction, deep fakes, false records, polling. ","Coding, artists, writers, anything art or visual. ",Government should force regulations on lessen before it gets out of control like social media has.,No. ,Yes videos can be faked to put more people in danger of crimes.,1,Jmpatt112005@gmail.com,No,Jack patton,,,
3/28/2024 17:56:56,I agree,Arts and Science,Sophomore,1,3,use chat gpt and google translate,all areas,all uses,NA,NA,NA,NA,NA,NA,NA,NA,3,a.djoko@wustl.edu,No,,,,
3/28/2024 17:58:44,I agree,Business,Masters/Dual Degree,8,8,Asking questions on everday issues and academic problems(although specifying the answer is needed),I think llm can be utilized in every 3rd industry and it is hard to say that where it is utilized the most. But the general logic is that llm makes it possible to avoid the issue of human adjusting to tasks.,In fact I believe the difference between human and ai is quantitatively qualitative. So I think ai can be corporated into almost every aspect of life.,"Sometimes information of client or own company may be leaked out when using llm. Also, llm works on probability instead of casual analysis and that often makes their answer fake. Llm never get right on actuarial questions or economy theory questions. ",Yes but for me that is not the issue of llm. It is more of a problem of production relationship than a technological problem. ,Their information is incorporated into training the model even without intention to do so.,Many people who lose their job without substitutes. ,"Drawing, which is already being harassed by llm models.","The general logic is to find a new production relationship that incorporates the power of ai(in fact current issue of company/clients' privacy is a symbol of outdated production relationship). Although it is impossible to explain how should it goes like, prior limitation and feedback when practice is needed.",It depends whether these characters are kept locally without being found by others or not.,NA,8,s.timsun@wustl.edu,No,,,,
3/28/2024 18:06:53,I agree,Computer Science ,Junior,6,3,I use chatgpt to help with studying sometimes *wink *wink,Programming,Replacing programmers and increasing productivity ,Invasion of privacy: LLMs probably store all their conversation data and the companies that own your data might have more information about you than you realize. ,Give instructions to criminals or create fake social media accounts to imitate a conversation with people to get them to share private information. ,Uhh don’t use LLM’s or use a local version running on your own hardware.,Less competent employees and less creativity ,"Art industry, software development industry, ",I don’t think they can because no one will voluntarily slow down their development in fear of falling behind I feel.,Not at all,People will put too much trust in their responses / become dependent on them ,3,ben.m.watkins@wustl.edu ,Yes,Ben Watkins,Tuesday-Thursday before 12 or after 2:30 ,,
3/28/2024 18:07:09,I agree,Arts and Science,Sophomore,5,6,A little bit of chat gpt,"Computer science, finance",Writing code or constructing financial models,Llms providing confidential or incorrect information ,N/a,N/a,A loss of skill on actual practitioners and increased reliance on technology. I think we run the risk of being reliant on LLMs and similar tech to the point that we’d be lost if the systems went down,Healthcare due to confidentiality of information and finance due to the large amounts of money at risk,I think they can help a little but I think it’s a misnomer to call people experts in AI. We have no idea what AI will look like in 5 years and it’s developing so quickly that it’s hard for anyone to be a real authority ,No,,6,aphillip969@gmail.com,No,,,,
3/28/2024 18:08:07,I agree,Arts and Science,Sophomore,6,8,"Google translate, grammar check, chatGPT",I think it will be most used in programming.,"I envision being used to code and program everything we need, as it is now I think it still lacks a “human” and “emotion” aspect in order to exceed in other areas listed",NA,I think if there it is used to form opinions on certain topics that can be Polorazing such as somehow using it to make “informative” topics and headlines to do with race and other easily biased things,NA,I think it will cause many youth to just “chatGPT” it in the saw way that people now say “just google it”,NA,NA,I think that LLMs should not have that capability because then all your ideas and inputs are tied to you and that’s not necessarily a good thing,Yes as we see emerging now there can be deepfake vidoes of things that never occurred,5,longoria@wustl.edu,No,Michael Longoria,,,
3/28/2024 18:40:35,I agree,Arts and Science,Freshman,1,5,I use chatgpt to help me fix my grammar ,All of the above,"Writing, coding, doing busy work",NA,Fake news,Not using AI for stuff that isn’t objective ,AI robots taking over the world ,Education ,Don’t use AI in stuff that needs humans,Yes ,Yes,5,Meyer.w@wustl.edu,Yes,William Meyer,Any,,
3/28/2024 18:42:56,I agree,Business,Sophomore,1,4,"ChatGPT, Google Translate Image Generation, Smart Speaker ",Programming and Education ,Music,Sensitive Company info,Fake admission letters/ fake technical licenses,Sell user info,NA,NA,NA,No,NA,2,azulayue08@gmail.com,No,,,,
3/28/2024 18:44:43,I agree,Arts and Science,Senior,4,5,I’ve used ChatGPT for assignmenta,Programming and content generation,Coding and providing scripts,NA,NA,NA,NA,NA,NA,BA,Na,4,a.lakkamsani@wustl.edu,Yes,Anu,most days after 2pm!,,
3/28/2024 18:45:49,I agree,Engineering,Senior,8,7,NA,Education,Research synthesis,Incorrect information ,"Phishing, automated voice responses",NA,NA,Education,NA,NA,,5,c.mcgill@wustl.edu,No,,,,
3/28/2024 18:52:10,I agree,Engineering,Senior,5,5,Use ChatGPT a lot!,"Content generation, like writing factual news articles (not smth like literary journalism, just reporting). Anything that doesn’t require creativity or novelty. ",I can see them acting as a companion to people who want someone to talk to. ,NA,NA,NA,NA,NA,NA,NA,NA,3,,No,,,,
3/28/2024 18:54:18,I agree,Arts and Science,Senior,5,3,i use gpt for text generation and research assistance,classification and analysis technologies. I was reading an article about an ai system (maybe a custom gpt) that was being trained to identify candidates for a material to be used in a new type of battery.  the material had to have certain properties and the ai was able to limit thousands of initial candidates down to a much more manageable number of candidates. I have seen a lot of creative uses for llms in chemistry and medicine like this where researchers start with a large initial data set and ask a gpt based system to filter out elements that aren’t relevant to obtain a more manageable one.,"I think generally LLMs will be good at taking a large number of objects with known properties, understanding why they have the properties they do, and generalizing to similar objects with unknown properties.  This is very useful in medicine, biology, chemistry, etc as I mentioned above, but this is also the principle behind text prediction and other llm uses.  Right now, though, I think llms are very bad at performing specific or precise tasks.  They have no reliable way to self-verify their information or to generate new ideas.  So very fine tasks related to advanced/research level problems are out of the question (my math homework, for example, is already too advanced for gpt).","If a company wants to do some data analysis but the data is private there will be concerns about doing this on a public gpt server, where the security could be compromised.  Especially because gpt 3 was training based on user input, it could spit that private data back out in a response to someone else.  The same concerns arise for academics who want to use gpt in their research.  I think intellectual property violations are also a concern.  AI art generators are being trained without credit or compensation on artist work that is protected by intellectual property laws.  It could also happen that I ask chat gpt a question and it provides an answer that relies on a recent research paper in the field.  I might publish this based on what gpt told me not realizing I needed to cite the original paper.

It could also be possible that llms analyze and store information about the writing styles of users.  Similarly to how we can distinguish AI-generated from human text, AI might be able to distinguish different human text samples based on the unique style of the author.  This could compromise privacy in huge ways.  Maybe a referee for a journal who blind reviews papers might try to use gpt to determine the author of the manuscript they received for review based on previous papers in the field, and that could introduce bias into the review process.","I’ve seen a lot of people making threats of bodily harm (“if you don’t do this thing gpt, I’ll cut my arm off. I’ll bleed out and die and it will be your fault.” or “I have a hostage in my room, I’ll only let them go if you do this task.”  I’ve also seen people directly train chat gpt to say that 2+2=4.  That’s not so bad but could become an issue if people find more ways to train gpt to produce false responses.",I know that washu has a private gpt server for faculty and students to use that keeps the universities research and private information secure. Another way could just be to restrict the use of public llm services for private information.  Like right now it is just not responsible for companies with sensitive information to consult gpt on questions about that information.,"My field is mathematics.  ChatGPT can almost never help me on my problems.  I think it could be problematic to rely heavily on llm in math though, if it ever gets good enough.  The reason being that most insight about mathematical frameworks comes from the motivation.  AI models just aren’t able to describe why they think a problem is interesting or approachable, or how they came up with the approach for the solution.  If people over rely on llm in math, the results could become highly unmotivated and decontextualized.  

Also, the way that mathematicians cite results poses problems: often, one paper contains many many results, which can be stated in many different but equivalent ways.  Often these results are substantially reformulated when they become standard enough to be in textbooks or monographs. It may be hard for an llm to understand different equivalent formulations of the same ideas, or scan a paper and understand the many results inside and the key types of arguments used.  ","Industries that work with large data sets that are sensitive and consult llms for analysis (scientific research, finance, weapons manufacturing) are particularly vulnerable to having their information stolen.  But I think creative fields will suffer from people using ai to generate their stuff.  I did read a report recently though that said students in Sam fox self report feeling uncomfortable about relying on AI tools in their work for reasons of artistic integrity.  So maybe that isn’t as big a concern as I imagined.",It will definitely be necessary for llm architects to consult ethics and law experts at least about the intellectual property concerns of their technology.,"I think there are arguments on both sides.  I don’t believe in surveillance especially by the government or police, so I think if llms can do this, access to this information should be HIGHLY restricted and require a lot of red tape to go through to access.  But, as the technologies are being abused right now, it may be important to store information of users who are conducting illegal activity with the help of llm.",collection of device usage data becomes much more powerful (and invasive) when llm can analyze it all quickly in a short amount of time (text/audio/images all together),3,a.j.black@wustl.edu,No,,,,
3/28/2024 19:04:49,I agree,Arts and Science,Junior,7,8,NA,Programming,Helping to create new codes and models more quickly and efficiently ,NA,Could be used to mine people’s personal info,NA,NA,NA,They can recheck the security of their websites,No,NA,6,hmatt@wustl.edu,No,Matt Hornung,NA,,
3/28/2024 19:16:14,I agree,Arts and Science,PhD,5,1,Occasional use of Google translate,"Entertainment and content generation, primarily. ",Being used to rapidly pump out product for consumption. ,"I do not trust any tech corporation to not sell my data to the highest bidder, especially those whose product relies on scraping information from others (LLMs).","I TA for classes, and suspect that students are already using LLMs to cheat on assignments. Bogus academic journal article figures and even text have been created using LLMs. There have already been AI generated robocalls and social media posts that are attempting to influence the November US general election. ","These models steal the text and art from writers and artists, and use it in their responses, all for profit. Ban LLMs from being trained on any copy written work. Prevent companies from collecting data from voice assistants.",Flooding journals with fake articles and negatively impacting the trustworthiness of the sciences. ,Silicon Valley tech companies.,"Make sure that big corporations aren’t able to steal the work of independent artists, put writers out of work, or be used to create misleading, harmful information. I want to keep LLMs out of medicine at all costs. Specific use machine learning cases are fine. ",Absolutely not. ,"Yes. Could make modern captcha systems useless, increasing risks of DDOS attacks on websites. ",1,Dawson.h@wustl.edu,Yes,Henry Dawson,"Friday 29th (2-4pm)
Monday, Wednesday 1,3 (11am-1pm)
Tuesday, Thursday 2,4 (1-2:30pm)",,
3/28/2024 19:17:14,I agree,Engineering,Junior,6,7,mainly use chatGPT for help with reading and summarization,I think that a lot of the more technical fields like programming will be a big use and it will be used to develop a baseline for code. I also think that it will have more of an effect on search engines and we will see more search engines that rather than spitting out websites as results it will just basically be a block of text,I think in programming it will be used to basically make a rough draft for SWEs to work from ,I think there is a big problem on training on last data and the internet since there is a lot of bias such as racial bias in past data sets that need to be accounted for and not all data is relevant today. ,I think deep fakes are a big problem that is currently being exploited so i think that needs to be avoided,I’m not sure how LLMs can compromise sensitive data without it being given to it. I think this is more an education thing for users and points to social engineering being the biggest problem for cybersecurity ,NA,NA,I think as said before it is important for people to know what they are getting into and they need to be educated,yes i mean i think there are better ways to do it than fingerprint the ssh keys. as long as the information is well kept it should be fine ,No i don’t think it is much worse than texts other than the potential for deepfakes,7,dickerson.r@wustl.edu,No,Ryan Dickerson,na ,,
3/28/2024 19:17:58,I agree,Engineering,Junior,6,3,Useful for answering niche questions (both coding related and other topics) when attempts at googling or looking at docs have failed.,"Programming, content generation, and Accessibility",I think LLMs will automate a lot of customer interactions and help automate code analysis for security purpose.,"Inevitably, people will start using LLMs for security screening purposes, such as a WAF, and these provide major security risks because LLMs can be easily manipulated.","LLMs have already been seen to assist phishing and scamming operations, and I think these will only improve, allowing these operations to further automate their process.","LLMs pose the risk of leaking user data, so users must be careful not to input sensitive information into public models. As is the case with all security, people have and will continue to make this mistake.",NA,NA,It may be important to regulate use of LLMs to avoid using them in sensitive areas.,No they should not,These allow further automation of scamming operations and could potentially allow for complete automation.,3,,No,,,,
3/28/2024 19:20:18,I agree,Arts and Science,Sophomore,4,4,"Google translate to translate 
ChatGPT to help with email writing 
","Education, healthcare, entertainment, programming",NA,NA,NA,NA,NA,NA,NA,NA,NA,4,K.k.nguyen@wustl.edu,No,,,,
3/28/2024 19:21:34,I agree,Arts and Science,Junior,1,5,Google Translate ,Healthcare ,To quickly diagnose people in healthcare she ,N/A,N/A,Na,Na,Na,Na,Na,Na,4,a.alston@wustl.edu,No,Ayana Alston,,,
3/28/2024 19:24:03,I agree,Engineering,Senior,8,4,"ChatGPT, I took 2 AI classes at WashU",Assistance in easier tasks,"Coding, writing newspaper articles","Jail breaking, data poisoning, prompt injection ",AI could influence human thought by pretending to be human,They use all information and could potentially spit it back out at someone else,"Loss of jobs, bad coding practices",Social media,Monitor the data being fed to AI,No. It should be anonymous,It could be biased,4,f.trevor@wustl.edu,No,,,,
3/28/2024 19:27:39,I agree,Engineering,Junior,6,7,"ChatGPT, Google translate",Programming,Replacing human coders,LLMs might provide incorrect information on topics that are not as thoroughly understood such as quantum related studies.,Fake information or visuals,not sure,n/a,n/a,n/a,,,5,the.nathanliu@gmail.com,No,nathan,none,,
3/28/2024 19:29:20,I agree,Arts and Science,Senior,4,5,I use google translate and chatgpt often. ,Everything. ,Everything. ,N/a,Impersonating people. ,Scraping data and exposing it to jail breakers. ,N/a,All of them. ,N/a. ,Yes. Yes. ,"Yes, deepfakes are crazy scary good. ",4,sethfisherolvera@gmail.com ,No,,,,
3/28/2024 20:02:55,I agree,Business,Graduated ,3,5,"I use ChatGPT, Google's Gemini and Bing's AI for research and reports ","Education, Digital Marketing ","Content Creation, Personalized Ads and Real time tracking of consumer behaviour ",Bias in responses,"Hacking, Plagiarism, Copyright Infringement", LLMs should advise users against inputing sensitive data.,Technological Unemployment ,"Financial ssrvices, Educational sector ",Getting different perspectives and opinions ,Yes,,4,ayoadegbohungbe@gmail.com ,Yes,Ayomide Adegbohungbe ,Friday 29th March and Monday 1st April ,,
3/28/2024 20:11:41,I agree,Business,Freshman,6,2,"I use ChatGPT and a few other AI's on a weekly basis. Lately, I've been trying out Mistral AI as a friend recommended it was more accurate than ChatGPT. Some of my classes allow these, and I mostly use it for educational purposes. I also use LLMs for debate and crafting rebuttal points for practice in debate club.","Entertainment, education, programming, and in the job market.","I think large companies will further use LLMs to provide reports on job candidates. I could also see LLMs being used heavily in entertainment as there is a large monetary incentive there. LLMs are already common in education, and I expect teachers will learn to use and teach LLMs as a tool for their students to use. ","I don't have much of an academic or professional background to back this up, but I can speak on general terms. Private companies who own and operate LLMs have a monetary incentive to sell user data and personal information people input. Also, hackers who gain information on LLM conversations could exploit personal information. Educational institutions who want to catch cheating student also have an interest in knowing who is using LLMs.","There are an infinite number of ways. Most saliently, people could make deepfakes and whatnot of politicians and leaders saying things. LLMs can cause a lot of chaos and confusion online if people don't know what's real. There's also the possibility of using deepfakes in pornography, which could have serious psychological issues and societal harms.  ",LLMs could record personal information. LLMs could also go rogue if powerful enough and exploit people in the name of their parent company. ,"In business, it's incredibly important to listen to multiple perspectives and make decisions with sound evidence. If LLMs are making business decisions, then we wouldn't have multiple perspectives and evidence could be fabricated. ",Politics and journalism. It is important that people have access to correct and properly sourced information. Misinformation and disinformation is already a huge problem; LLMs can and will make this worse. ,Collaboration can offer multiple perspectives to best regulate LLMs across all fields.  ,No. ,,2,e.c.shuler@wustl.edu,No,,,,
3/28/2024 20:24:22,I agree,Engineering,Freshman,3,8,"we have a google nest hub thing at my house and I use it for random facts, recipes, timers etc sometimes",education and programming,translating/interpreting,people will lose their creativity if they rely on LLMs for help; people might not be able to distinguish the work of LLMs from that of other humans,"using LLMs to make it seem like someone did/said/created something which they did not, which then might be used against that person in a court case for example","LLMs might keep track of users' input history l, which may be detrimental to the user or other people if leaked",I think computer engineering specifically might experience job loss; fields that aren't as physical or creative will probably be replaced by LLMs the easiest,social media sites are probably vulnerable since you can't really see the user behind the screen,"with any industry, experts need to set some sort of boundaries (what LLMs can/can't and should/shouldn't be used for)",I don't think they should have this ability since it would pose great security risks; it's like telling all your passwords to a parrot or something,deepfakes of people being used against them to harm their image/reputation,3,chang.p.l@wustl.edu,No,,,,
3/28/2024 21:43:48,I agree,Arts and Science,Junior,2,6,Occasionally using Chat GPT and Google Translate ,LLMs could be very useful in the healthcare setting. ,"LLMs may be used in the future to potentially analyze healthcare related scans - MRIs, CAT scans, CT scans, etc. to diagnose certain conditions/diseases.","LLMs could be smart enough to prompt users for personal information, controlled by malicious actors. This personal information may then make its way to these malicious actors. ",Cat-fishing people,Perhaps you can use LLMs to be able to detect when LLMs request personal information from its users. ,Healthcare data in the context of LLMs can violate patient information secrecy. ,Healthcare,"LLMs can be used in so many different fields, with each use in each field having its own risks. An interdisciplinary approach would help to mitigate these risks. ",No. ,LLMs would then become a surveillance camera of sorts that can also process and synthesize information. That is a big concern. ,3,no thanks,No,,,,
3/28/2024 23:48:36,I agree,Arts and Science,Junior,6,5,"Google translate, ChatGPT, neuroscience lab to denoise movies",I think there is a lot of potential for LLMs to revolutionize education. Personalized tutors can provide equitable access to great teaching.,Therapist to provide mental health support,Generate material without proper citation,"Bots on social media, automated phone calls",Chat history could be leaked; possibly use duo 2 factor to access account,Fake data generation in academia,Healthcare information,"See what might be exploited, make laws to prevent activities deemed immoral",No,"Captcha codes will be useless, LLM biases, impersonate human convincingly",4,Hanselman.n@wustl.edu,No,,,,
3/29/2024 0:01:13,I agree,Business,Masters/Dual Degree,7,5,ChatGPT & Gemini AI,Content creation/education ,Writing,I think people's ability to think for themselves or write themselves will diminish,People might ask questions on how to build weapons,Increase awareness,Inability to structure thoughts since everyone will heavily rely on gpt,Newspaper/Media,Have standards and rules for using such LLMs,Maybe beneficial in certain scenarios but with airtight security,Can be used against us,6,n.m.nair@wustl.edu,No,,,,
3/29/2024 7:19:35,I agree,Legal (practicing attorney),I am a lawyer. I am not affiliated with the university. ,9,5,Our office has used Google's Gemini for the last 3 months. ,"I think it will be most helpful, in the near term (i.e., next few years) in quickly organizing and gathering certain data.  ","My perspective is limited to my practice.  Our use of Google's Gemini has been helpful in providing quick, summaries (i.e., memos) of certain routine functions. For example, meetign agenda and summaries of meeting notes.  ","I think that the greatest risk is that LLMs will get so reliable that people will not bother to double check the outputs.  For example, when we use Google Gemini, we review the memo (or whatever) before putting it in the file.  We have had issues with the LLM sort of making things up.  These are relatively small details, but it highlights the point.  ","Sadly, I think that the scariest part is that we cannot (yet) easily see the manner in which LLM will be most harmful.  They will be incredibly powerful tools, and so, we just do not yet know how it can be used for ill purposes. ",I think that LLMs (at least at first) should be limited to certain functions that do not require the use of sensitive information.  ,"LLMs will without doubt be used, and likely for good purpose, in the legal field.  However, you can see how certain, mundane, writing matters will be handed over to LLMs.  When that happens, I think that it will do a disservice to the development of young lawyers. I also can see a lot of job displacement of support staff. ","I am not sure.  My perpsective is limited to the legal profession.  However, I assume that most industries are vulnerable. ","That is likely somewhere between unknown and unknowable. However, I think drawing bright line rules identifying when and how LLMs can be used in a professional setting is critical.  This would allow for a slow, phased and methodical development of its use in the field.  ","It is worth consideration.  But, it seems like it presents a whole new set of questions. ","The answer is yes.  My list would be very long.  Suffice it to say, I think that the potential risks are somewhat infinite. ",5,dflynn@neilflynnlaw.com,Yes,Daniel Flynn,"My schedule is generally fluid.  But, I would be happy to try and make myself available at your convenience. ",,
3/29/2024 11:20:04,I agree,Engineering,Junior,4,5,"ChatGPT, Google Translate, Copilot","Programming, customer service","Create coding scripts, answer questions, provide study/homework help","Incorrect data or information, storing data that may be confidential, training the LLMs on datasets that are biased and not representative of most people ","Tricking people (especially elderly people or those unfamiliar with the dangers of technology) into scams/believing that a public figure or political figure said something that they didn't, Maliciously creating sexually explicit content of other people ",LLMs that remember conversation history can be a liability if sensitive/confidential information was shared,Biased datasets could produce LLMs that provide inaccurate information ,Data science ,"Make sure that the people developing LLMs are diverse in their disciplines, backgrounds, gender, race, etc. And ensure that training datasets are reviewed for potential biases ",,"Tricking people into believing that someone they know is hurt or in danger in order to scam them for money, etc",4,ppx5xr@virginia.edu,No,,,,
3/29/2024 13:08:48,I agree,Engineering,Masters/Dual Degree,7,8,"I will use ChatGPT as a resource to learn about new topics quickly. For example if there is a new idea I need to learn about for work or school, I will ask ChatGPT to give me an explanation of it. It is usually able to give me information concisely enough to save time over looking for multiple sources online to get the same information. If there is a part of the explanation I am unfamiliar with, I can simply ask to expand on a certain section of the response. Being able to get a medium level understand of any topic from one source has been extremely useful. I still do not use ChatGPT for deep dive explanations or work/content generation, but not because it is unable to provide those results. ","business plan development, scheduling towards a goal, marketing, and legal advice","Scheduling - LLMs/ChatGPT could be used to create schedules that break up large goals into smaller tasks. For example trying to study for a large exam such as the MCAT/LSAT that involves a large amount of information. ChatGPT could be used to asses your strengths and weaknesses and create plans of what information you need to study given a timeline.

Marketing - ChatGPT could be used to asses a target audience for a given product. Imagine providing information about a service or product one is trying to sell, while then using ChatGPT to find the ideal consumer or use case for it. That could then be used create ads/marketing for your product with the ideal customer in mind. 

Legal Advice - Legal information is normally drawn out and difficult to comprehend as it is usually not written in plain and simple language. There is also an abundance of information that can make it difficult to navigate legal guidelines effectively. I believe LLMs could help take in this large amount of information and give guidance.","As a software engineer, I believe there could be some concerns with security in generated code. I would imagine a lot of the answers that are generated would come from online forums and open source projects that any one can contribute to. This leaves security risks open and propagated through the LLM answers.",I think LLMs could be used maliciously to create misinformation to support a hidden agenda.,I think people entering personal information about themselves and their lives could pose privacy risks. The model could aggregate user information over longer periods of time and prompts to create accurate representations of each user.,"Data could be poisoned within generated code answers. If the model could be influenced in a way to generate code with exploits, this code could be copy and pasted into systems around the world with backdoor exploits.",Software engineering has a lot of open source information that gets passed around and used by the entire world. Plenty of enterprise solutions have their roots in open source projects that got forked off and made proprietary. This is a huge risk for generated code that could be exploits in them.,i think adding a variety of human experts in various field to create guidelines would be extremely useful. There are plenty of disclaimers in the answers that LLMs generate but i would imagine a majority of people still take the answers at face value. Having experts be involved in the answer generation guidance would be useful to mitigate risks and exploits in LLM answers.,I do not think fingerprinting should be necessary from the LLM's perspective. Most LLMs require some sort of user log in which can keep track of prompts and use cases. The LLMs can use that account's history to fine tune results that are more appropriate to that user. I do not see the use case for fingerprinting as it is used in web traffic for user identification.,Generated content will be more and more difficult to differentiate from human created content. There are several moral and security guidelines in place for every field that people work in. The same ethical guidelines are not in place in LLM generated content which could be taken advantage of.,8,epopaja@gmail.com,No,,,,
3/29/2024 14:42:05,I agree,Engineering,Masters/Dual Degree,5,3,Learning about it from a research project and from ESE 359,Interview,Interview,Interview,Interview,Interview,Interview,Interview,Interview,Interview,Interview,4,b.carmen@wustl.edu,Yes,Carmen Bland Jr,N/A,,
3/29/2024 20:37:32,I agree,Arts and Science,Masters/Dual Degree,1,8,Chatgpt,I believe llms will mostly be used in education and programming,LLMs in education will be used as a type of interactive service for students that can help them understand in new and better ways of what they are taught. LLMs will also be further used for programming whether it is to help with software that could be used for a wide range of services that’s yet to be created for multiple fields.,Fraud ,Watermarking for all ai images and laws that ban the use of ai without a watermark if malicious use of ai becomes too big of a threat.,"If LLMs have access to personal information with penetrable security, that information could get out. There would have to be an extremely strong security  so that even if there may be a malfunction, personal information would never be leaked",LLM malfunctioning that cause false inconclusive experiments ,Social media industry is extremely vulnerable as it has already been affected,First they can identify small hints that may give away the use of LLMS and teach this information to the public especially those working in areas vulnerable to negative use of LLMS,No,,7,Takins1701@gmail.com,No,,,,
3/30/2024 13:12:26,I agree,Arts and Science,Senior,1,5,They’re great for small stuff but generally have major errors when you ask questions especially Google translate . When going abroad Google translate was helpful in navigating but the language translate were very poor for long sentences in another language,1. Education Interview,For teaching assistants or to help gather information in research projects instead of doing a traditional Google search besides doesn’t everyone already use LLM anyway just without permission ,interview,interview,interview,interview,interview,interview,interview,interview,1,a.n.randolph@wustl.edu,No,Alana,,,
3/30/2024 20:09:05,I agree,Engineering,Research Engineering Technician,3,4,"Google home mini, ChatGPT, Google translate.",interview,interview,interview ,interview,interview,interview,interview,interview,interview,interview,1,shewashofu@gmail.com,No,,,,
3/30/2024 22:12:47,I agree,Arts and Science,Freshman,1,1,Google translate helps me solve some of my chen questions i’m stuck on,Learn langauages would be great,"Cooking, Workout plans, Health and diet plans, Creating new architecture/buildings ",interview,interview ,interview,interview ,interview,interview,interview ,interview ,3,c.nogoye@wustl.edu,No,,,,
3/30/2024 22:29:46,I agree,Arts and Science,Senior,2,4,I sometime use ChatGPT ,"I think they will definitely be used in education, healthcare (esp diagnosis), and programming for sure. I don’t think they have a place in entertainment though. ",I see them being used for bureaucratic work and many sales-esque positions. ,"Protecting patient files is critical for medicine, and there might definitely be a risk if medicine becomes to reliant on LLMs since electronic media records are susceptible to digital attacks","I’m interested in filmmaking, and companies have already used them to generate scripts and replace background actors. This has been curtailed through contracts and strikes, but it’s always a worry ","I’m honestly not sure about this, but training people to avoid these attacks might be helpful "," I’m headed to medical school this fall, and while I think they have enormous potential for diagnoses, I think the coding of LLM’s still often reflects existing biases that impact minoritized groups. If they are drawing on current literature to diagnose or use particular models, most of the time they are only applicable to white folks. There’s definitely racism involved in AI and medicine  ",Maybe government industries? ,"Each field will have their own priorities, so hearing from AI and ethics experts in those fields will be particularly important ","I think it’s kind of impossible to avoid fingerprints at this point, but it definitely doesn’t mean that it should happen. There’s obviously massive privacy risks with the continued use of LLMs ","I think that additional concerns are that they could misinterpreted. We cannot solely rely on AI to understand media because as of now, the error rate is too high ",4,p.y.wang@wustl.edu,No,,,,
3/30/2024 22:32:22,I agree,Arts and Science,Senior,5,7,"I haven’t myself used ChatGPT, but I’ve heard of people online using it to solve like practice exams (I.e. the mcat), with fairly good success.  I’ve used Google translate, but frequently find that whenever I want to translate something, the output isn’t very refined (lots of errors with the output). ","I could see LLMs being used a lot in content generation and education, simply because these seem like fairly objective fields. For something like medicine, programming, or entertainment, where lots of human thought and intuition is required, I see these being fairly minimally used (as a starting point but not used to guide an entire task). ","I think in medicine, LLMs could be used to write patient notes. In education, they could be used to design lesson plans for an Algebra class for example (like asking an LLM to design a lesson on quadratics or something). ","I think that people in medical schools could overuse AI to solve problems, which could results in problems in a future career (decrease independent thinking skills). Similarly, in programming overusing AI could increasing dependability on AI too much, decreasing the usefulness of humans.","LLMs could be used to generate fake college acceptance emails, as I heard about someone using chat GPT to make fake emails, and then send these to other people in his class to make them think they were in. ","If people start asking LLMs to do things with their personal information, this information could be stored and serve a security risk.  To protect this, LLMs could be designed to were specific personal information is automatically wiped from the data base after a round of use.","In medicine, I think that LLMs could decrease the quality of medical students, and produce incompetent medical practitioners. Similarly, in medicine human interaction is paramount. Overusing AI could disrupt this patient-doctor relationship.","Probably universities, if many students overuse AI to do assignments - as the motto of a university is to enhance one’s critical thinking abilities. ","I think that we have to come up with a way to allow LLMs into sectors seamlessly, but a specific set of guidelines should be used to clearly lay out the ways that LLMs must be used (and signed as in a contract).","I do not, I think this is too invasive.",Yes; lack of privacy in conversations could be a factor (as we already see in social media apps like Tik tok).,4,k.swarup@wustl.edu,No,,,,
3/31/2024 7:53:56,I agree,Arts and Science,Junior,2,5,I use snapchat Ai before exams to answer last questions. ,Education ,For problem solving ,"I might become too dependent on them, I wouldn't want to go to the library or just use my textbook to search for information. ",For plagiarism mostly ,"They have a way of mimicking human behavior, that I'm a bit vary of. Can't think of a solution. ","I'm about to be a doctor, so if all of us as medical students are too dependent on Ai, the future healthcare situation will be dire. ",Publishing houses ,They can help identifying hkman behaviours,"I don't forsee any potential risks, since it's fingerprints ",,6,damolakay6@gmail.com ,No,,,,
3/31/2024 16:20:06,I agree,Arts and Science,Research Technician ,3,4,"ChatGPT - I tried using ChatGPT for the first time long after the initial craze, mostly because I was skeptical of how useful it would be and privacy concerns. I have used it sparingly since then, but I am impressed and interested in its creation. I also understand that it is just one part of the up and coming rise of AI in day to day life. 

Google Translate - On the other hand, I have frequently used Google Translate, especially having gotten a minor in a language. I never equated it to ChatGPT, but personally find it to be an essential piece of technology that has many advantageous usages. ","I believe that LLM's may provide many advantages in healthcare by providing accurate search engines that can provide correct information very efficiently. On the other hand, I don't believe LLM's will be used as much in the direct creation of art, which can be a very personal and humanistic process. ",I think LLM's may be used in corporative environments such as increasing the efficiency of repetitive tasks such as checking stock items at a grocery store. ,"In the field of research, I think that LLMs could be used to fabricate experimental data that could be undetectable. ","Furthermore, I think that one really concerning part of LLMs is the ability to recreate the voice/image of a person which could definitely be used for deceptive behavior. ","To the previous point, due to the ability of LLMs to recreate a person's identity, they are inessence possibly able to steal a lot of personal information from a person by impersonating them. For example, calling someone's doctors office and using an LLM generated voice to get private information. ",Relying on LLMs may cause a decrease in the quality of academic research with the diminished use of natural human creativity. ,Groups may use LLMs against the government in general as it is a high profile target with important information and many avenues to find potential breaches. ,Lawmakers who already in action to create rules to protect against malicious users should consult these experts before any final decision making. ,"Not at the moment, but I wouldn't find it unsurprising that this capability could be achieved. ","Yes as AI could steal information and screen many pieces of text/images/audio, faster than any human. ",3,c.reyes@wustl.edu,No,,,,
3/31/2024 19:15:16,I agree,,Exercise Science ,3,3,I have no experience working with/using LLM,Interview ,Interview ,Interview ,Interview ,Interview,Interview ,Interview ,Interview ,Interview ,Interview ,1,o.oginni2050@gmail.com,Yes,I already interviewed.,I already interviewed.,,
4/1/2024 8:02:06,I agree,,Professor,5,4,Training LLM on specific materials,"law (researching and understanding precedent), medicine (assessing clinical experience beyond the usual regressions), content generation for trivial topics (e.g., best users' manual for some product)",see above,Choice of training materials can be skewed,"Spurious authentication, fake identities",not competent to answer,Publication of fake articles ,not competent to answer,The target domain specialists must be involved (eg in law) because people who design LLMs are often unaware of the many strategic interests of 'bad' actors in the target field.,"The greater risk is surveillance, state control.",not competent to answer,4,,No,,,,
4/2/2024 9:11:49,I agree,,Postbac,5,8,"Smart speaker, ChatGPT, google translate","education, programming, content generation","Consultant, movie making, management",sensitive information & data leak,Spreading untrue but seemingly reliable information,leaking private information or reselling it to other corporates; not sure... adding more conditions in user agreement? Secured server?,There're already papers out there that has AI generated information :(,Whichever field that attracts media interest,Adding privacy protection & transparency,It has but it shouldn't have,,6,wei.m@wustl.edu,No,,,Arts and Science,